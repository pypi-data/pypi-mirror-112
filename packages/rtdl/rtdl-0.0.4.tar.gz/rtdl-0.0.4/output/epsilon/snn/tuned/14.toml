seed = 14

[data]
path = 'data/epsilon'

[model]
d_layers = [ 880, 918, 918, 918, 918, 918, 918, 156 ]
dropout = 0.07718793551068272

[training]
eval_batch_size = 8192
lr = 8.026735720963361e-05
lr_n_decays = 0
n_epochs = 1000000000
optimizer = 'adam'
patience = 16
weight_decay = 0
