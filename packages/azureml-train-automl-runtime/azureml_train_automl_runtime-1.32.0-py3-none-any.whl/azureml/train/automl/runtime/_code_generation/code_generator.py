# ---------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# ---------------------------------------------------------
"""Functions used to generate Python script for customer usage."""
from typing import Any, cast, Optional, List, Tuple
import json
import os
import pickle
import shutil
import tempfile

from azureml.core import Run, Workspace
from azureml.automl.core.shared import constants
from azureml.automl.runtime.featurization.transformer_and_mapper import (
    TransformerAndMapper,
)
from azureml.automl.runtime.featurization import DataTransformer
from azureml.automl.runtime.featurizer.transformer.timeseries import (
    TimeSeriesTransformer,
)
from azureml.automl.runtime.shared.model_wrappers import (
    RegressionPipeline,
    ForecastingPipelineWrapper,
    PreFittedSoftVotingClassifier,
    PreFittedSoftVotingRegressor,
    StackEnsembleBase
)
from azureml.automl.core import _codegen_utilities
from azureml.automl.core.constants import FeaturizationRunConstants
from azureml.train.automl import _constants_azureml
from sklearn.pipeline import Pipeline
from sklearn_pandas import DataFrameMapper
from sklearn_pandas.pipeline import TransformerPipeline


GET_DATASET_FUNC_NAME = "get_training_dataset"
PREPARE_DATA_FUNC_NAME = "prepare_data"
GET_WEIGHTS_FUNC_NAME = "get_class_weights"
FEATURIZE_FUNC_NAME = "generate_data_transformation_config"
PREPROC_FUNC_NAME = "generate_preprocessor_config"
MODEL_FUNC_NAME = "generate_algorithm_config"
BUILD_MODEL_FUNC_NAME = "build_model_pipeline"
TRAIN_MODEL_FUNC_NAME = "train_model"


def _get_setup_run(parent_run: Run) -> Run:
    setup_run_list = list(
        parent_run._client.run.get_runs_by_run_ids(
            run_ids=["{}_{}".format(parent_run.id, "setup")]
        )
    )
    # if this is a local run there will be no setup iteration
    if len(setup_run_list) == 0:
        setup_run = parent_run
    else:
        setup_run = setup_run_list[0]
    return setup_run


def generate_full_script(child_run: Run) -> str:
    output = [
        "# ---------------------------------------------------------",
        "# Copyright (c) Microsoft Corporation. All rights reserved.",
        "# ---------------------------------------------------------",
        "# This file has been autogenerated by the Azure Automated Machine Learning SDK.",
        "\n",
    ]

    parent_run = child_run.parent
    setup_run = _get_setup_run(parent_run)

    parent_run_details = parent_run.get_details()
    properties = parent_run.properties
    input_datasets = parent_run_details.get("inputDatasets", [])
    training_dataset_id = None
    # validation_dataset_id = None

    for input_dataset in input_datasets:
        consumption_block = input_dataset.get("consumptionDetails", {})
        dataset_name = consumption_block.get("inputName", None)

        if dataset_name == "training_data":
            training_dataset_id = input_dataset["dataset"].id
        # elif dataset_name == 'validation_data':
        #     validation_dataset_id = input_dataset['dataset'].id

    assert training_dataset_id is not None, "No training dataset found"

    settings_json = properties.get(_constants_azureml.Properties.AML_SETTINGS)
    settings_obj = json.loads(settings_json)
    task_type = settings_obj.get("task_type")
    label_column_name = settings_obj.get("label_column_name")
    weight_column_name = settings_obj.get("weight_column_name")

    featurization_enabled = (
        settings_obj.get("featurization", "off") != "off" or settings_obj.get("preprocess", False) is not False
    )
    is_timeseries = settings_obj.get("is_timeseries", False)

    tempdir = None
    featurizer_config = None
    timeseries_transformer = None
    timeseries_stddev = None    # type: Optional[float]

    try:
        tempdir = tempfile.mkdtemp()

        # Retrieve the preprocessor/algorithm sklearn pipeline
        child_run.download_file(_constants_azureml.MODEL_PATH, tempdir)
        pipeline_path = os.path.join(
            tempdir, os.path.basename(_constants_azureml.MODEL_PATH)
        )
        with open(pipeline_path, "rb") as f:
            pipeline = pickle.load(f)

        if featurization_enabled:
            if isinstance(pipeline.steps[0][1], DataTransformer):
                featurizer_config = pipeline.steps[0][1].transformer_and_mapper_list
            elif isinstance(pipeline.steps[0][1], TimeSeriesTransformer):
                timeseries_transformer = pipeline.steps[0][1]
                timeseries_stddev = cast(float, pipeline.stddev)
            else:
                # Retrieve the featurization config if the model doesn't have the data transformer
                featurizer_config_remote_path = setup_run.properties.get(
                    FeaturizationRunConstants.CONFIG_PROP,
                    FeaturizationRunConstants.CONFIG_PATH,
                )
                setup_run.download_file(featurizer_config_remote_path, tempdir)
                featurizer_config_path = os.path.join(
                    tempdir, os.path.basename(featurizer_config_remote_path)
                )
                with open(featurizer_config_path, "rb") as f:
                    featurizer_config = pickle.load(f)
    finally:
        if tempdir is not None:
            shutil.rmtree(tempdir, ignore_errors=True)

    output.append(get_dataset_code(child_run.experiment.workspace, training_dataset_id))
    output.append("\n")
    output.append(get_prepare_data_code())
    output.append("\n")
    output.append(get_class_weights_code(weight_column_name))
    output.append("\n")
    if is_timeseries:
        if featurization_enabled and timeseries_transformer:
            output.append(get_timeseries_transformer_code(timeseries_transformer))
            output.append("\n")
        output.append(get_modelwrapper_code(pipeline))
        output.append("\n")
        output.append(get_build_timeseries_model_pipeline_code(timeseries_stddev, featurization_enabled))
    else:
        output.append(get_transformer_code(task_type, featurizer_config))
        output.append("\n")
        output.append(get_model_code(pipeline))
    output.append("\n")
    output.append(get_train_model_code(label_column_name, weight_column_name))
    output.append("\n")
    output.append(get_scriptrun_code(task_type))
    output.append("\n")

    return "\n".join(output)


def get_dataset_code(workspace: Workspace, dataset_id: str) -> str:
    output = [
        "def {}():".format(GET_DATASET_FUNC_NAME),
        "from azureml.core import Dataset, Workspace",
        "",
        "ws = Workspace(subscription_id='{}', resource_group='{}', workspace_name='{}')".format(
            workspace._subscription_id,
            workspace._resource_group,
            workspace._workspace_name,
        ),
        "dataset = Dataset.get_by_id(workspace=ws, id='{}')".format(dataset_id),
        "return dataset.to_pandas_dataframe()",
    ]

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_prepare_data_code() -> str:
    # TODO: make stuff from data_transformation.py publicly visible here
    # such as label encoding, dropping NaN, etc
    output = ["def {}(df):".format(PREPARE_DATA_FUNC_NAME), "return df"]

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_class_weights_code(weight_column_name: Optional[str]) -> str:
    # TODO: Double check what needs to be done when weight_column_name is not None
    output = ["def {}(df):".format(GET_WEIGHTS_FUNC_NAME)]
    if weight_column_name is None:
        output.append("return None")
    else:
        output.extend(
            [
                "weight_column_name = '{}'".format(weight_column_name),
                "sample_weights = df[weight_column_name].values",
                "return sample_weights",
            ]
        )

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_transformer_code(
    task_type: str, featurizer_config: Optional[List[TransformerAndMapper]]
) -> str:
    output = ["def {}():".format(FEATURIZE_FUNC_NAME)]

    imports = {
        _codegen_utilities.get_import(DataFrameMapper),
        _codegen_utilities.get_import(DataTransformer),
        _codegen_utilities.get_import(TransformerAndMapper),
        _codegen_utilities.get_import(TransformerPipeline),
        ("numpy", "nan", float),
    }

    if featurizer_config is not None:
        for trm in featurizer_config:
            for feature in trm.mapper.features:
                for step in feature[1].steps:
                    imports.add(_codegen_utilities.get_import(step[1]))
                    if hasattr(step[1], "_get_imports"):
                        imports.update(step[1]._get_imports())

    output.extend(_codegen_utilities.generate_import_statements(sorted(list(imports))))
    output.append("")

    output.append("transformer_and_mapper_list = []")

    if featurizer_config is not None:
        for i, trm in enumerate(featurizer_config):
            i += 1
            tr_str = "transformer{}".format(i)
            output.append("{} = {}".format(tr_str, trm.mapper.features))
            params = {"input_df": trm.mapper.input_df, "sparse": trm.mapper.sparse}
            repr_str = _codegen_utilities.generate_repr_str(
                DataFrameMapper, params, features="transformer{}".format(i)
            )
            output.append("mapper{} = {}".format(i, repr_str))
            output.append(
                "tm{0} = TransformerAndMapper(transformers={1}, mapper=mapper{0})".format(
                    i, tr_str
                )
            )
            output.append("transformer_and_mapper_list.append(tm{})".format(i))
            output.append("")

    output.append("dt = DataTransformer(task='{}')".format(task_type))
    output.append("dt.transformer_and_mapper_list = transformer_and_mapper_list")
    output.append("")
    output.append("return dt")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_timeseries_transformer_code(
    timeseries_transformer: TimeSeriesTransformer,
) -> str:
    output = ["def {}():".format(FEATURIZE_FUNC_NAME)]

    imports = set(timeseries_transformer._get_imports())
    imports.add(("numpy", "nan", float))
    imports.add(_codegen_utilities.get_import(TimeSeriesTransformer))

    output.extend(_codegen_utilities.generate_import_statements(sorted(list(imports))))
    output.append("")

    output.append("transformer_list = []")

    assert timeseries_transformer.pipeline is not None
    for i, step in enumerate(timeseries_transformer.pipeline.steps):
        i += 1
        transformer = step[1]
        tr_str = "transformer{}".format(i)
        output.append("{} = {}".format(tr_str, transformer))
        output.append("transformer_list.append(('{}', {}))".format(step[0], tr_str))
        output.append("")

    output.append("pipeline = Pipeline(steps=transformer_list)")

    params = timeseries_transformer.get_params(deep=False)
    params.pop("pipeline")
    pipeline_type = params.pop("pipeline_type")
    pipeline_type_str = "{}.{}".format(
        pipeline_type.__class__.__name__, pipeline_type.name
    )

    tst_repr = _codegen_utilities.generate_repr_str(
        timeseries_transformer.__class__,
        params,
        pipeline="pipeline",
        pipeline_type=pipeline_type_str,
    )

    output.append("tst = {}".format(tst_repr))
    output.append("")
    output.append("return tst")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_model_code(sklearn_pipeline: Pipeline) -> str:
    output = []
    model = sklearn_pipeline.steps[-1][1]
    if isinstance(model, (PreFittedSoftVotingRegressor, PreFittedSoftVotingClassifier)):
        params = model.get_params(deep=False)
        estimators = params.pop("estimators")

        # Generate one pair of functions for each estimator
        for i, estimator in enumerate(estimators):
            output.append(get_preprocessor_code(estimator[1], i))
            output.append("\n")
            output.append(get_modelwrapper_code(estimator[1], i))
            output.append("\n")

        # Generate the main function
        # Modified version of get_modelwrapper_code() such that instead of using the estimators
        # from the model directly, we call out to the functions we generated above
        func_output = ["def {}():".format(MODEL_FUNC_NAME)]
        imports = [
            _codegen_utilities.get_import(model.__class__),
            _codegen_utilities.get_import(Pipeline)
        ]
        if hasattr(model, "_get_imports"):
            imports.extend(model._get_imports())

        func_output.extend(_codegen_utilities.generate_import_statements(imports))
        func_output.append("")

        for i in range(len(estimators)):
            func_output.append("pipeline_{0} = Pipeline(steps=[('preproc', {1}_{0}()), ('model', {2}_{0}())])".format(
                i, PREPROC_FUNC_NAME, MODEL_FUNC_NAME
            ))

        estimators_output = [
            '['
        ] + ["('model_{0}', pipeline_{0}),".format(i) for i in range(len(estimators))] + [
            ']'
        ]
        estimators_str = _codegen_utilities.indent_multiline_string('\n'.join(estimators_output))

        repr_str = _codegen_utilities.generate_repr_str(model.__class__, params, estimators=estimators_str)
        func_output.append("algorithm = {}".format(repr_str))
        func_output.append("")
        func_output.append("return algorithm")

        code_body = "\n".join(func_output)
        output.append(_codegen_utilities.indent_multiline_string(code_body))

        output.append("\n")
        output.append(get_build_model_pipeline_code(True))
    elif isinstance(model, StackEnsembleBase):
        params = model.get_params(deep=False)
        estimators = params.pop("base_learners")
        meta_estimator = params.pop("meta_learner")

        # Generate one pair of functions for each estimator
        for i, estimator in enumerate(estimators):
            output.append(get_preprocessor_code(estimator[1], i))
            output.append("\n")
            output.append(get_modelwrapper_code(estimator[1], i))
            output.append("\n")

        output.append(get_modelwrapper_code(('meta', meta_estimator), "meta"))
        output.append("\n")

        # Generate the main function
        # Modified version of get_modelwrapper_code() such that instead of using the estimators
        # from the model directly, we call out to the functions we generated above
        func_output = ["def {}():".format(MODEL_FUNC_NAME)]
        imports = [
            _codegen_utilities.get_import(model.__class__),
            _codegen_utilities.get_import(Pipeline)
        ]
        if hasattr(model, "_get_imports"):
            imports.extend(model._get_imports())

        func_output.extend(_codegen_utilities.generate_import_statements(imports))
        func_output.append("")

        func_output.append("meta_learner = Pipeline(steps=[('preproc', {1}_{0}()), ('model', {2}_{0}())])".format(
            "meta", PREPROC_FUNC_NAME, MODEL_FUNC_NAME
        ))
        func_output.append("")

        for i in range(len(estimators)):
            func_output.append("pipeline_{0} = Pipeline(steps=[('model', {1}_{0}())])".format(
                i, MODEL_FUNC_NAME
            ))

        estimators_output = [
            '['
        ] + ["('model_{0}', pipeline_{0}),".format(i) for i in range(len(estimators))] + [
            ']'
        ]
        estimators_str = _codegen_utilities.indent_multiline_string('\n'.join(estimators_output))
        meta_estimator_str = "meta_learner"

        repr_str = _codegen_utilities.generate_repr_str(
            model.__class__,
            params,
            base_learners=estimators_str,
            meta_learner=meta_estimator_str
        )
        func_output.append("algorithm = {}".format(repr_str))
        func_output.append("")
        func_output.append("return algorithm")

        code_body = "\n".join(func_output)
        output.append(_codegen_utilities.indent_multiline_string(code_body))

        output.append("\n")
        output.append(get_build_model_pipeline_code(True))
    else:
        output.append(get_preprocessor_code(sklearn_pipeline.steps[-2]))
        output.append("\n")
        output.append(get_modelwrapper_code(sklearn_pipeline.steps[-1]))
        output.append("\n")
        output.append(get_build_model_pipeline_code(False))

    return "\n".join(output)


def get_preprocessor_code(model: Tuple[str, Any], name: Optional[Any] = None) -> str:
    if name is None:
        output = ["def {}():".format(PREPROC_FUNC_NAME)]
    else:
        output = ["def {}_{}():".format(PREPROC_FUNC_NAME, name)]

    # preproc_name, preproc_obj = sklearn_pipeline.steps[-2]
    preproc_name, preproc_obj = model

    imports = [_codegen_utilities.get_import(preproc_obj.__class__)]
    if hasattr(preproc_obj, "_get_imports"):
        imports.extend(preproc_obj._get_imports())

    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    output.append("preproc = {}".format(preproc_obj))
    output.append("")
    output.append("return preproc")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_modelwrapper_code(model: Tuple[str, Any], name: Optional[Any] = None) -> str:
    if name is None:
        output = ["def {}():".format(MODEL_FUNC_NAME)]
    else:
        output = ["def {}_{}():".format(MODEL_FUNC_NAME, name)]

    # model_name, model_obj = sklearn_pipeline.steps[-1]
    model_name, model_obj = model

    imports = [_codegen_utilities.get_import(model_obj.__class__)]
    if hasattr(model_obj, "_get_imports"):
        imports.extend(model_obj._get_imports())

    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    output.append("algorithm = {}".format(model_obj))
    output.append("")
    output.append("return algorithm")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_build_model_pipeline_code(is_ensemble: bool) -> str:
    output = ["def {}():".format(BUILD_MODEL_FUNC_NAME)]

    imports = [_codegen_utilities.get_import(Pipeline)]
    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    output.append("pipeline = Pipeline(")
    output.append("    steps=[('dt', {}()),".format(FEATURIZE_FUNC_NAME))
    if is_ensemble:
        output.append("           ('ensemble', {}())]".format(MODEL_FUNC_NAME))
    else:
        output.append("           ('preproc', {}()),".format(PREPROC_FUNC_NAME))
        output.append("           ('model', {}())]".format(MODEL_FUNC_NAME))
    output.append(")")
    output.append("")
    output.append("return pipeline")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_build_timeseries_model_pipeline_code(stddev: Optional[float], featurization_enabled: bool) -> str:
    output = ["def {}():".format(BUILD_MODEL_FUNC_NAME)]

    imports = [
        _codegen_utilities.get_import(Pipeline),
        _codegen_utilities.get_import(ForecastingPipelineWrapper),
    ]
    output.extend(_codegen_utilities.generate_import_statements(imports))
    output.append("")

    if featurization_enabled:
        output.append("pipeline = Pipeline(")
        output.append("    steps=[('tst', {}()),".format(FEATURIZE_FUNC_NAME))
        output.append("           ('model', {}())]".format(MODEL_FUNC_NAME))
        output.append(")")
    else:
        output.append("pipeline = Pipeline(")
        output.append("    steps=[('model', {}())]".format(MODEL_FUNC_NAME))
        output.append(")")
    output.append(
        "forecast_pipeline_wrapper = ForecastingPipelineWrapper(pipeline, stddev={})".format(
            stddev
        )
    )
    output.append("")
    output.append("return forecast_pipeline_wrapper")

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_train_model_code(
    label_column_name: str, weight_column_name: Optional[str]
) -> str:
    output = [
        "def {}(dataframe):".format(TRAIN_MODEL_FUNC_NAME),
        "label_column_name = '{}'".format(label_column_name),
    ]

    if weight_column_name:
        output.append("class_weights_column_name = '{}'".format(weight_column_name))

    output.extend(
        [
            "model_pipeline = {}()".format(BUILD_MODEL_FUNC_NAME),
            "",
            "# extract the features, target and sample weight arrays",
        ]
    )

    if weight_column_name:
        output.append("sample_weights = dataframe[class_weights_column_name]")
        output.append(
            "X = dataframe.drop([label_column_name, class_weights_column_name])"
        )
    else:
        output.append("X = dataframe.drop([label_column_name])")

    output.extend(
        [
            "y = dataframe[label_column_name].values" "",
            "model = model_pipeline.fit(X, y)",
            "return model",
        ]
    )

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)


def get_scriptrun_code(task_type: str) -> str:
    output = [
        "if __name__ == '__main__':",
        "# The following code is for when running this code as part of an AzureML script run.",
        "from azureml.core import Run",
        "run = Run.get_context()",
        "",
        "df = {}()".format(GET_DATASET_FUNC_NAME),
        "df = {}(df)".format(PREPARE_DATA_FUNC_NAME),
        "sample_weights = {}(df)".format(GET_WEIGHTS_FUNC_NAME),
        "model = {}(df)".format(TRAIN_MODEL_FUNC_NAME),
        "y_pred = model.predict(X_test)",
        "",
    ]

    # TODO: Scoring (we need to handle the validation dataset)
    # Need to fill out the parameters
    """
    if task_type == constants.Tasks.CLASSIFICATION:
        output.extend([
            "from azureml.automl.runtime.shared.score.scoring import score_classification",
            "y_pred = model.predict(X_test)",
            "metrics = score_classification()"
        ])
    elif task_type == constants.Tasks.REGRESSION:
        output.extend([
            "from azureml.automl.runtime.shared.score.scoring import score_regression",
            "y_pred = model.predict(X_test)",
            "metrics = score_regression()"
        ])
    elif task_type == constants.Tasks.FORECASTING:
        # TODO: make sure we can just call model.predict() for forecasting
        output.extend([
            "from azureml.automl.runtime.shared.score.scoring import score_forecasting",
            "y_pred = model.predict(X_test)",
            "metrics = score_forecasting()"
        ])
    else:
        # Other tasks are not implemented
        pass
    """

    # TODO: Emit code to log metrics

    output.extend(
        [
            "import pickle",
            "with open('model.pkl', 'wb') as f:",
            "    pickle.dump(model, f)",
            "run.upload_file('outputs/model.pkl', 'model.pkl')",
        ]
    )

    code_body = "\n".join(output)
    return _codegen_utilities.indent_multiline_string(code_body)
