# coding: utf-8

"""
    Karbon Platform Services API reference.

    OpenAPI documentation for public facing Karbon Platform Services API  This API documentation is generated from source code using go-swagger. Do not edit the generated kps_api.json directly!  # noqa: E501

    OpenAPI spec version: 1.0
    Contact: karbon-platform-services-api@nutanix.com
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six
from kps_api.models.category_info import CategoryInfo  # noqa: F401,E501
from kps_api.models.data_ifc_endpoint import DataIfcEndpoint  # noqa: F401,E501
from kps_api.models.data_source import DataSource  # noqa: F401,E501
from kps_api.models.retention_info import RetentionInfo  # noqa: F401,E501
from kps_api.models.transformation_args import TransformationArgs  # noqa: F401,E501


class DataStream(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'data_ifc_endpoints': 'list[DataIfcEndpoint]',
        'aws_cloud_region': 'str',
        'aws_stream_type': 'str',
        'az_stream_type': 'str',
        'cloud_creds_id': 'str',
        'cloud_type': 'str',
        'data_retention': 'list[RetentionInfo]',
        'data_type': 'str',
        'description': 'str',
        'destination': 'str',
        'edge_stream_type': 'str',
        'enable_sampling': 'bool',
        'end_point': 'str',
        'end_point_uri': 'str',
        'gcp_cloud_region': 'str',
        'gcp_stream_type': 'str',
        'id': 'str',
        'name': 'str',
        'origin': 'str',
        'origin_id': 'str',
        'origin_selectors': 'list[CategoryInfo]',
        'out_data_ifc': 'DataSource',
        'project_id': 'str',
        'sampling_interval': 'float',
        'size': 'float',
        'state': 'str',
        'transformation_args_list': 'list[TransformationArgs]'
    }

    attribute_map = {
        'data_ifc_endpoints': 'DataIfcEndpoints',
        'aws_cloud_region': 'awsCloudRegion',
        'aws_stream_type': 'awsStreamType',
        'az_stream_type': 'azStreamType',
        'cloud_creds_id': 'cloudCredsId',
        'cloud_type': 'cloudType',
        'data_retention': 'dataRetention',
        'data_type': 'dataType',
        'description': 'description',
        'destination': 'destination',
        'edge_stream_type': 'edgeStreamType',
        'enable_sampling': 'enableSampling',
        'end_point': 'endPoint',
        'end_point_uri': 'endPointURI',
        'gcp_cloud_region': 'gcpCloudRegion',
        'gcp_stream_type': 'gcpStreamType',
        'id': 'id',
        'name': 'name',
        'origin': 'origin',
        'origin_id': 'originId',
        'origin_selectors': 'originSelectors',
        'out_data_ifc': 'outDataIfc',
        'project_id': 'projectId',
        'sampling_interval': 'samplingInterval',
        'size': 'size',
        'state': 'state',
        'transformation_args_list': 'transformationArgsList'
    }

    def __init__(self, data_ifc_endpoints=None, aws_cloud_region=None, aws_stream_type=None, az_stream_type=None, cloud_creds_id=None, cloud_type=None, data_retention=None, data_type=None, description=None, destination=None, edge_stream_type=None, enable_sampling=None, end_point=None, end_point_uri=None, gcp_cloud_region=None, gcp_stream_type=None, id=None, name=None, origin=None, origin_id=None, origin_selectors=None, out_data_ifc=None, project_id=None, sampling_interval=None, size=None, state=None, transformation_args_list=None):  # noqa: E501
        """DataStream - a model defined in Swagger"""  # noqa: E501
        self._data_ifc_endpoints = None
        self._aws_cloud_region = None
        self._aws_stream_type = None
        self._az_stream_type = None
        self._cloud_creds_id = None
        self._cloud_type = None
        self._data_retention = None
        self._data_type = None
        self._description = None
        self._destination = None
        self._edge_stream_type = None
        self._enable_sampling = None
        self._end_point = None
        self._end_point_uri = None
        self._gcp_cloud_region = None
        self._gcp_stream_type = None
        self._id = None
        self._name = None
        self._origin = None
        self._origin_id = None
        self._origin_selectors = None
        self._out_data_ifc = None
        self._project_id = None
        self._sampling_interval = None
        self._size = None
        self._state = None
        self._transformation_args_list = None
        self.discriminator = None
        if data_ifc_endpoints is not None:
            self.data_ifc_endpoints = data_ifc_endpoints
        if aws_cloud_region is not None:
            self.aws_cloud_region = aws_cloud_region
        if aws_stream_type is not None:
            self.aws_stream_type = aws_stream_type
        if az_stream_type is not None:
            self.az_stream_type = az_stream_type
        if cloud_creds_id is not None:
            self.cloud_creds_id = cloud_creds_id
        if cloud_type is not None:
            self.cloud_type = cloud_type
        self.data_retention = data_retention
        self.data_type = data_type
        if description is not None:
            self.description = description
        self.destination = destination
        if edge_stream_type is not None:
            self.edge_stream_type = edge_stream_type
        self.enable_sampling = enable_sampling
        if end_point is not None:
            self.end_point = end_point
        if end_point_uri is not None:
            self.end_point_uri = end_point_uri
        if gcp_cloud_region is not None:
            self.gcp_cloud_region = gcp_cloud_region
        if gcp_stream_type is not None:
            self.gcp_stream_type = gcp_stream_type
        if id is not None:
            self.id = id
        self.name = name
        self.origin = origin
        if origin_id is not None:
            self.origin_id = origin_id
        self.origin_selectors = origin_selectors
        if out_data_ifc is not None:
            self.out_data_ifc = out_data_ifc
        if project_id is not None:
            self.project_id = project_id
        if sampling_interval is not None:
            self.sampling_interval = sampling_interval
        self.size = size
        if state is not None:
            self.state = state
        self.transformation_args_list = transformation_args_list

    @property
    def data_ifc_endpoints(self):
        """Gets the data_ifc_endpoints of this DataStream.  # noqa: E501

        Data Ifc endpoints connected to this datastream  # noqa: E501

        :return: The data_ifc_endpoints of this DataStream.  # noqa: E501
        :rtype: list[DataIfcEndpoint]
        """
        return self._data_ifc_endpoints

    @data_ifc_endpoints.setter
    def data_ifc_endpoints(self, data_ifc_endpoints):
        """Sets the data_ifc_endpoints of this DataStream.

        Data Ifc endpoints connected to this datastream  # noqa: E501

        :param data_ifc_endpoints: The data_ifc_endpoints of this DataStream.  # noqa: E501
        :type: list[DataIfcEndpoint]
        """

        self._data_ifc_endpoints = data_ifc_endpoints

    @property
    def aws_cloud_region(self):
        """Gets the aws_cloud_region of this DataStream.  # noqa: E501

        AWS region. Required if cloudType == AWS  # noqa: E501

        :return: The aws_cloud_region of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._aws_cloud_region

    @aws_cloud_region.setter
    def aws_cloud_region(self, aws_cloud_region):
        """Sets the aws_cloud_region of this DataStream.

        AWS region. Required if cloudType == AWS  # noqa: E501

        :param aws_cloud_region: The aws_cloud_region of this DataStream.  # noqa: E501
        :type: str
        """
        allowed_values = ["us-east-2", "us-east-1", "us-west-1", "us-west-2", "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-south-1", "ap-southeast-1", "ap-southeast-2", "ca-central-1", "cn-north-1", "cn-northwest-1", "eu-central-1", "eu-west-1", "eu-west-2", "eu-west-3", "sa-east-1"]  # noqa: E501
        if aws_cloud_region not in allowed_values:
            raise ValueError(
                "Invalid value for `aws_cloud_region` ({0}), must be one of {1}"  # noqa: E501
                .format(aws_cloud_region, allowed_values)
            )

        self._aws_cloud_region = aws_cloud_region

    @property
    def aws_stream_type(self):
        """Gets the aws_stream_type of this DataStream.  # noqa: E501

        Type of the DataStream at AWS Cloud. Required if cloudType == AWS  # noqa: E501

        :return: The aws_stream_type of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._aws_stream_type

    @aws_stream_type.setter
    def aws_stream_type(self, aws_stream_type):
        """Sets the aws_stream_type of this DataStream.

        Type of the DataStream at AWS Cloud. Required if cloudType == AWS  # noqa: E501

        :param aws_stream_type: The aws_stream_type of this DataStream.  # noqa: E501
        :type: str
        """
        allowed_values = ["Kinesis", "SQS", "S3", "DynamoDB"]  # noqa: E501
        if aws_stream_type not in allowed_values:
            raise ValueError(
                "Invalid value for `aws_stream_type` ({0}), must be one of {1}"  # noqa: E501
                .format(aws_stream_type, allowed_values)
            )

        self._aws_stream_type = aws_stream_type

    @property
    def az_stream_type(self):
        """Gets the az_stream_type of this DataStream.  # noqa: E501

        Type of the DataStream at Azure Cloud. Required if cloudType == Azure  # noqa: E501

        :return: The az_stream_type of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._az_stream_type

    @az_stream_type.setter
    def az_stream_type(self, az_stream_type):
        """Sets the az_stream_type of this DataStream.

        Type of the DataStream at Azure Cloud. Required if cloudType == Azure  # noqa: E501

        :param az_stream_type: The az_stream_type of this DataStream.  # noqa: E501
        :type: str
        """
        allowed_values = ["Blob"]  # noqa: E501
        if az_stream_type not in allowed_values:
            raise ValueError(
                "Invalid value for `az_stream_type` ({0}), must be one of {1}"  # noqa: E501
                .format(az_stream_type, allowed_values)
            )

        self._az_stream_type = az_stream_type

    @property
    def cloud_creds_id(self):
        """Gets the cloud_creds_id of this DataStream.  # noqa: E501

        CloudCreds id. Required if destination == Cloud  # noqa: E501

        :return: The cloud_creds_id of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._cloud_creds_id

    @cloud_creds_id.setter
    def cloud_creds_id(self, cloud_creds_id):
        """Sets the cloud_creds_id of this DataStream.

        CloudCreds id. Required if destination == Cloud  # noqa: E501

        :param cloud_creds_id: The cloud_creds_id of this DataStream.  # noqa: E501
        :type: str
        """

        self._cloud_creds_id = cloud_creds_id

    @property
    def cloud_type(self):
        """Gets the cloud_type of this DataStream.  # noqa: E501

        Cloud type, required if destination == Cloud  # noqa: E501

        :return: The cloud_type of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._cloud_type

    @cloud_type.setter
    def cloud_type(self, cloud_type):
        """Sets the cloud_type of this DataStream.

        Cloud type, required if destination == Cloud  # noqa: E501

        :param cloud_type: The cloud_type of this DataStream.  # noqa: E501
        :type: str
        """
        allowed_values = ["AWS", "GCP", "Azure"]  # noqa: E501
        if cloud_type not in allowed_values:
            raise ValueError(
                "Invalid value for `cloud_type` ({0}), must be one of {1}"  # noqa: E501
                .format(cloud_type, allowed_values)
            )

        self._cloud_type = cloud_type

    @property
    def data_retention(self):
        """Gets the data_retention of this DataStream.  # noqa: E501

        Retention policy for this DataStream. Multiple RetentionInfo are combined using AND semantics. For example, retain data for 1 month AND up to 2 TB of data.  # noqa: E501

        :return: The data_retention of this DataStream.  # noqa: E501
        :rtype: list[RetentionInfo]
        """
        return self._data_retention

    @data_retention.setter
    def data_retention(self, data_retention):
        """Sets the data_retention of this DataStream.

        Retention policy for this DataStream. Multiple RetentionInfo are combined using AND semantics. For example, retain data for 1 month AND up to 2 TB of data.  # noqa: E501

        :param data_retention: The data_retention of this DataStream.  # noqa: E501
        :type: list[RetentionInfo]
        """
        if data_retention is None:
            raise ValueError("Invalid value for `data_retention`, must not be `None`")  # noqa: E501

        self._data_retention = data_retention

    @property
    def data_type(self):
        """Gets the data_type of this DataStream.  # noqa: E501

        Data type of the DataStream. For example, Temperature, Pressure, Image, Multiple, etc.  # noqa: E501

        :return: The data_type of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._data_type

    @data_type.setter
    def data_type(self, data_type):
        """Sets the data_type of this DataStream.

        Data type of the DataStream. For example, Temperature, Pressure, Image, Multiple, etc.  # noqa: E501

        :param data_type: The data_type of this DataStream.  # noqa: E501
        :type: str
        """
        if data_type is None:
            raise ValueError("Invalid value for `data_type`, must not be `None`")  # noqa: E501

        self._data_type = data_type

    @property
    def description(self):
        """Gets the description of this DataStream.  # noqa: E501

        The description of the DataStream  # noqa: E501

        :return: The description of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._description

    @description.setter
    def description(self, description):
        """Sets the description of this DataStream.

        The description of the DataStream  # noqa: E501

        :param description: The description of this DataStream.  # noqa: E501
        :type: str
        """

        self._description = description

    @property
    def destination(self):
        """Gets the destination of this DataStream.  # noqa: E501

        Destination of the DataStream. Either Edge or Cloud or DataInterface.  # noqa: E501

        :return: The destination of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._destination

    @destination.setter
    def destination(self, destination):
        """Sets the destination of this DataStream.

        Destination of the DataStream. Either Edge or Cloud or DataInterface.  # noqa: E501

        :param destination: The destination of this DataStream.  # noqa: E501
        :type: str
        """
        if destination is None:
            raise ValueError("Invalid value for `destination`, must not be `None`")  # noqa: E501
        allowed_values = ["Edge", "Cloud", "DataInterface"]  # noqa: E501
        if destination not in allowed_values:
            raise ValueError(
                "Invalid value for `destination` ({0}), must be one of {1}"  # noqa: E501
                .format(destination, allowed_values)
            )

        self._destination = destination

    @property
    def edge_stream_type(self):
        """Gets the edge_stream_type of this DataStream.  # noqa: E501

        Type of the DataStream at Edge. Required if destination == Edge  # noqa: E501

        :return: The edge_stream_type of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._edge_stream_type

    @edge_stream_type.setter
    def edge_stream_type(self, edge_stream_type):
        """Sets the edge_stream_type of this DataStream.

        Type of the DataStream at Edge. Required if destination == Edge  # noqa: E501

        :param edge_stream_type: The edge_stream_type of this DataStream.  # noqa: E501
        :type: str
        """
        allowed_values = ["Kafka", "ElasticSearch", "MQTT", "None"]  # noqa: E501
        if edge_stream_type not in allowed_values:
            raise ValueError(
                "Invalid value for `edge_stream_type` ({0}), must be one of {1}"  # noqa: E501
                .format(edge_stream_type, allowed_values)
            )

        self._edge_stream_type = edge_stream_type

    @property
    def enable_sampling(self):
        """Gets the enable_sampling of this DataStream.  # noqa: E501

        Whether to turn sampling on. If true, then samplingInterval should be set as well.  # noqa: E501

        :return: The enable_sampling of this DataStream.  # noqa: E501
        :rtype: bool
        """
        return self._enable_sampling

    @enable_sampling.setter
    def enable_sampling(self, enable_sampling):
        """Sets the enable_sampling of this DataStream.

        Whether to turn sampling on. If true, then samplingInterval should be set as well.  # noqa: E501

        :param enable_sampling: The enable_sampling of this DataStream.  # noqa: E501
        :type: bool
        """
        if enable_sampling is None:
            raise ValueError("Invalid value for `enable_sampling`, must not be `None`")  # noqa: E501

        self._enable_sampling = enable_sampling

    @property
    def end_point(self):
        """Gets the end_point of this DataStream.  # noqa: E501

        End point of datastream. User specifies the endpoint.  # noqa: E501

        :return: The end_point of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._end_point

    @end_point.setter
    def end_point(self, end_point):
        """Sets the end_point of this DataStream.

        End point of datastream. User specifies the endpoint.  # noqa: E501

        :param end_point: The end_point of this DataStream.  # noqa: E501
        :type: str
        """

        self._end_point = end_point

    @property
    def end_point_uri(self):
        """Gets the end_point_uri of this DataStream.  # noqa: E501

        Endpoint URI Derived from existing fields required false  # noqa: E501

        :return: The end_point_uri of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._end_point_uri

    @end_point_uri.setter
    def end_point_uri(self, end_point_uri):
        """Sets the end_point_uri of this DataStream.

        Endpoint URI Derived from existing fields required false  # noqa: E501

        :param end_point_uri: The end_point_uri of this DataStream.  # noqa: E501
        :type: str
        """

        self._end_point_uri = end_point_uri

    @property
    def gcp_cloud_region(self):
        """Gets the gcp_cloud_region of this DataStream.  # noqa: E501

        GCP region. Required if cloudType == GCP  # noqa: E501

        :return: The gcp_cloud_region of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._gcp_cloud_region

    @gcp_cloud_region.setter
    def gcp_cloud_region(self, gcp_cloud_region):
        """Sets the gcp_cloud_region of this DataStream.

        GCP region. Required if cloudType == GCP  # noqa: E501

        :param gcp_cloud_region: The gcp_cloud_region of this DataStream.  # noqa: E501
        :type: str
        """
        allowed_values = ["northamerica-northeast1", "us-central1", "us-west1", "us-east4", "us-east1", "southamerica-east1", "europe-west1", "europe-west2", "europe-west3", "europe-west4", "asia-south1", "asia-southeast1", "asia-east1", "asia-northeast1", "australia-southeast1"]  # noqa: E501
        if gcp_cloud_region not in allowed_values:
            raise ValueError(
                "Invalid value for `gcp_cloud_region` ({0}), must be one of {1}"  # noqa: E501
                .format(gcp_cloud_region, allowed_values)
            )

        self._gcp_cloud_region = gcp_cloud_region

    @property
    def gcp_stream_type(self):
        """Gets the gcp_stream_type of this DataStream.  # noqa: E501

        Type of the DataStream at GCP Cloud. Required if cloudType == GCP  # noqa: E501

        :return: The gcp_stream_type of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._gcp_stream_type

    @gcp_stream_type.setter
    def gcp_stream_type(self, gcp_stream_type):
        """Sets the gcp_stream_type of this DataStream.

        Type of the DataStream at GCP Cloud. Required if cloudType == GCP  # noqa: E501

        :param gcp_stream_type: The gcp_stream_type of this DataStream.  # noqa: E501
        :type: str
        """
        allowed_values = ["PubSub", "CloudDatastore", "CloudSQL", "CloudStorage"]  # noqa: E501
        if gcp_stream_type not in allowed_values:
            raise ValueError(
                "Invalid value for `gcp_stream_type` ({0}), must be one of {1}"  # noqa: E501
                .format(gcp_stream_type, allowed_values)
            )

        self._gcp_stream_type = gcp_stream_type

    @property
    def id(self):
        """Gets the id of this DataStream.  # noqa: E501

        ID of the entity Maximum character length is 64 for project, category, and runtime environment, 36 for other entity types.  # noqa: E501

        :return: The id of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._id

    @id.setter
    def id(self, id):
        """Sets the id of this DataStream.

        ID of the entity Maximum character length is 64 for project, category, and runtime environment, 36 for other entity types.  # noqa: E501

        :param id: The id of this DataStream.  # noqa: E501
        :type: str
        """

        self._id = id

    @property
    def name(self):
        """Gets the name of this DataStream.  # noqa: E501

        Name of the DataStream. This is the published output (Kafka topic) name.  # noqa: E501

        :return: The name of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this DataStream.

        Name of the DataStream. This is the published output (Kafka topic) name.  # noqa: E501

        :param name: The name of this DataStream.  # noqa: E501
        :type: str
        """
        if name is None:
            raise ValueError("Invalid value for `name`, must not be `None`")  # noqa: E501

        self._name = name

    @property
    def origin(self):
        """Gets the origin of this DataStream.  # noqa: E501

        The origin of the DataStream. Either 'Data Source' or 'Data Stream'  # noqa: E501

        :return: The origin of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._origin

    @origin.setter
    def origin(self, origin):
        """Sets the origin of this DataStream.

        The origin of the DataStream. Either 'Data Source' or 'Data Stream'  # noqa: E501

        :param origin: The origin of this DataStream.  # noqa: E501
        :type: str
        """
        if origin is None:
            raise ValueError("Invalid value for `origin`, must not be `None`")  # noqa: E501
        allowed_values = ["Data Source", "Data Stream"]  # noqa: E501
        if origin not in allowed_values:
            raise ValueError(
                "Invalid value for `origin` ({0}), must be one of {1}"  # noqa: E501
                .format(origin, allowed_values)
            )

        self._origin = origin

    @property
    def origin_id(self):
        """Gets the origin_id of this DataStream.  # noqa: E501

        If origin == 'Data Stream', then originId can be used in place of originSelectors to specify the origin data stream ID if the origin data stream is unique.  # noqa: E501

        :return: The origin_id of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._origin_id

    @origin_id.setter
    def origin_id(self, origin_id):
        """Sets the origin_id of this DataStream.

        If origin == 'Data Stream', then originId can be used in place of originSelectors to specify the origin data stream ID if the origin data stream is unique.  # noqa: E501

        :param origin_id: The origin_id of this DataStream.  # noqa: E501
        :type: str
        """

        self._origin_id = origin_id

    @property
    def origin_selectors(self):
        """Gets the origin_selectors of this DataStream.  # noqa: E501

        A list of CategoryInfo used as criteria to filter sources applicable to this DataStream.  # noqa: E501

        :return: The origin_selectors of this DataStream.  # noqa: E501
        :rtype: list[CategoryInfo]
        """
        return self._origin_selectors

    @origin_selectors.setter
    def origin_selectors(self, origin_selectors):
        """Sets the origin_selectors of this DataStream.

        A list of CategoryInfo used as criteria to filter sources applicable to this DataStream.  # noqa: E501

        :param origin_selectors: The origin_selectors of this DataStream.  # noqa: E501
        :type: list[CategoryInfo]
        """
        if origin_selectors is None:
            raise ValueError("Invalid value for `origin_selectors`, must not be `None`")  # noqa: E501

        self._origin_selectors = origin_selectors

    @property
    def out_data_ifc(self):
        """Gets the out_data_ifc of this DataStream.  # noqa: E501


        :return: The out_data_ifc of this DataStream.  # noqa: E501
        :rtype: DataSource
        """
        return self._out_data_ifc

    @out_data_ifc.setter
    def out_data_ifc(self, out_data_ifc):
        """Sets the out_data_ifc of this DataStream.


        :param out_data_ifc: The out_data_ifc of this DataStream.  # noqa: E501
        :type: DataSource
        """

        self._out_data_ifc = out_data_ifc

    @property
    def project_id(self):
        """Gets the project_id of this DataStream.  # noqa: E501

        ID of parent project. This should be required, but is not marked as such due to backward compatibility.  # noqa: E501

        :return: The project_id of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._project_id

    @project_id.setter
    def project_id(self, project_id):
        """Sets the project_id of this DataStream.

        ID of parent project. This should be required, but is not marked as such due to backward compatibility.  # noqa: E501

        :param project_id: The project_id of this DataStream.  # noqa: E501
        :type: str
        """

        self._project_id = project_id

    @property
    def sampling_interval(self):
        """Gets the sampling_interval of this DataStream.  # noqa: E501

        Sampling interval in seconds. The sampling interval applies to each mqtt/kafka topic separately.  # noqa: E501

        :return: The sampling_interval of this DataStream.  # noqa: E501
        :rtype: float
        """
        return self._sampling_interval

    @sampling_interval.setter
    def sampling_interval(self, sampling_interval):
        """Sets the sampling_interval of this DataStream.

        Sampling interval in seconds. The sampling interval applies to each mqtt/kafka topic separately.  # noqa: E501

        :param sampling_interval: The sampling_interval of this DataStream.  # noqa: E501
        :type: float
        """

        self._sampling_interval = sampling_interval

    @property
    def size(self):
        """Gets the size of this DataStream.  # noqa: E501

        Current size of the DataStream output in GB.  # noqa: E501

        :return: The size of this DataStream.  # noqa: E501
        :rtype: float
        """
        return self._size

    @size.setter
    def size(self, size):
        """Sets the size of this DataStream.

        Current size of the DataStream output in GB.  # noqa: E501

        :param size: The size of this DataStream.  # noqa: E501
        :type: float
        """
        if size is None:
            raise ValueError("Invalid value for `size`, must not be `None`")  # noqa: E501

        self._size = size

    @property
    def state(self):
        """Gets the state of this DataStream.  # noqa: E501

        State of this entity  # noqa: E501

        :return: The state of this DataStream.  # noqa: E501
        :rtype: str
        """
        return self._state

    @state.setter
    def state(self, state):
        """Sets the state of this DataStream.

        State of this entity  # noqa: E501

        :param state: The state of this DataStream.  # noqa: E501
        :type: str
        """

        self._state = state

    @property
    def transformation_args_list(self):
        """Gets the transformation_args_list of this DataStream.  # noqa: E501

        List of transformations (together with their args) to apply to the origin data to produce the destination data. Could be empty if no transformation required. Each entry is the id of the transformation Script to apply to input from origin to produce output to destination.  # noqa: E501

        :return: The transformation_args_list of this DataStream.  # noqa: E501
        :rtype: list[TransformationArgs]
        """
        return self._transformation_args_list

    @transformation_args_list.setter
    def transformation_args_list(self, transformation_args_list):
        """Sets the transformation_args_list of this DataStream.

        List of transformations (together with their args) to apply to the origin data to produce the destination data. Could be empty if no transformation required. Each entry is the id of the transformation Script to apply to input from origin to produce output to destination.  # noqa: E501

        :param transformation_args_list: The transformation_args_list of this DataStream.  # noqa: E501
        :type: list[TransformationArgs]
        """
        if transformation_args_list is None:
            raise ValueError("Invalid value for `transformation_args_list`, must not be `None`")  # noqa: E501

        self._transformation_args_list = transformation_args_list

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(DataStream, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, DataStream):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
