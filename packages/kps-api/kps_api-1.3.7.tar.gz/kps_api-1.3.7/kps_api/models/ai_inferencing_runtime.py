# coding: utf-8

"""
    Karbon Platform Services API reference.

    OpenAPI documentation for public facing Karbon Platform Services API  This API documentation is generated from source code using go-swagger. Do not edit the generated kps_api.json directly!  # noqa: E501

    OpenAPI spec version: 1.0
    Contact: karbon-platform-services-api@nutanix.com
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six


class AIInferencingRuntime(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'accelerator_device': 'str',
        'framework_type': 'str'
    }

    attribute_map = {
        'accelerator_device': 'AcceleratorDevice',
        'framework_type': 'FrameworkType'
    }

    def __init__(self, accelerator_device=None, framework_type=None):  # noqa: E501
        """AIInferencingRuntime - a model defined in Swagger"""  # noqa: E501
        self._accelerator_device = None
        self._framework_type = None
        self.discriminator = None
        if accelerator_device is not None:
            self.accelerator_device = accelerator_device
        if framework_type is not None:
            self.framework_type = framework_type

    @property
    def accelerator_device(self):
        """Gets the accelerator_device of this AIInferencingRuntime.  # noqa: E501


        :return: The accelerator_device of this AIInferencingRuntime.  # noqa: E501
        :rtype: str
        """
        return self._accelerator_device

    @accelerator_device.setter
    def accelerator_device(self, accelerator_device):
        """Sets the accelerator_device of this AIInferencingRuntime.


        :param accelerator_device: The accelerator_device of this AIInferencingRuntime.  # noqa: E501
        :type: str
        """
        allowed_values = ["CPU", "GPU"]  # noqa: E501
        if accelerator_device not in allowed_values:
            raise ValueError(
                "Invalid value for `accelerator_device` ({0}), must be one of {1}"  # noqa: E501
                .format(accelerator_device, allowed_values)
            )

        self._accelerator_device = accelerator_device

    @property
    def framework_type(self):
        """Gets the framework_type of this AIInferencingRuntime.  # noqa: E501


        :return: The framework_type of this AIInferencingRuntime.  # noqa: E501
        :rtype: str
        """
        return self._framework_type

    @framework_type.setter
    def framework_type(self, framework_type):
        """Sets the framework_type of this AIInferencingRuntime.


        :param framework_type: The framework_type of this AIInferencingRuntime.  # noqa: E501
        :type: str
        """
        allowed_values = ["TensorFlow1.13.1", "TensorFlow2.1.0"]  # noqa: E501
        if framework_type not in allowed_values:
            raise ValueError(
                "Invalid value for `framework_type` ({0}), must be one of {1}"  # noqa: E501
                .format(framework_type, allowed_values)
            )

        self._framework_type = framework_type

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(AIInferencingRuntime, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, AIInferencingRuntime):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
